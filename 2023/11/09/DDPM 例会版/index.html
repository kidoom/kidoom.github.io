<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>初识DDPM 算法理解（例会版） | L's Blog</title><meta name="author" content="kidoom"><meta name="copyright" content="kidoom"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="DDPM  概率扩散模型1. 前提引入：1.1正态分布正态分布是非常常见的连续几率随机分布。 对于一个骰子 假如我们随机掷骰子，随着次数的增多 每个点数出现的概率：  继续增加骰子，重复这个实验：  发现随着采样次数的增加 七点的值会逐渐增加成为一个折线 假设我们继续增加骰子，重复这个实验：  随着骰子数量的增多，折线越来越接近这样一个曲线 即为概率密度曲线 这样的概率分布在自然界中十分常见">
<meta property="og:type" content="article">
<meta property="og:title" content="初识DDPM 算法理解（例会版）">
<meta property="og:url" content="https://kidoom.github.io/2023/11/09/DDPM%20%E4%BE%8B%E4%BC%9A%E7%89%88/index.html">
<meta property="og:site_name" content="L&#39;s Blog">
<meta property="og:description" content="DDPM  概率扩散模型1. 前提引入：1.1正态分布正态分布是非常常见的连续几率随机分布。 对于一个骰子 假如我们随机掷骰子，随着次数的增多 每个点数出现的概率：  继续增加骰子，重复这个实验：  发现随着采样次数的增加 七点的值会逐渐增加成为一个折线 假设我们继续增加骰子，重复这个实验：  随着骰子数量的增多，折线越来越接近这样一个曲线 即为概率密度曲线 这样的概率分布在自然界中十分常见">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://encrypted-tbn3.gstatic.com/images?q=tbn:ANd9GcRhgfFsJpHeDrIFa_fRqFkKCURen03oJEh7TF5zqiXknM_gVPa1">
<meta property="article:published_time" content="2023-11-08T16:00:00.000Z">
<meta property="article:modified_time" content="2023-11-10T05:33:34.181Z">
<meta property="article:author" content="kidoom">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://encrypted-tbn3.gstatic.com/images?q=tbn:ANd9GcRhgfFsJpHeDrIFa_fRqFkKCURen03oJEh7TF5zqiXknM_gVPa1"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://kidoom.github.io/2023/11/09/DDPM%20%E4%BE%8B%E4%BC%9A%E7%89%88/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: 'Just',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: [object Object]
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '初识DDPM 算法理解（例会版）',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-11-10 13:33:34'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.3.0"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">Loading...</div></div></div><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://blog-1314366587.cos.ap-nanjing.myqcloud.com/blog%2FDTicon.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">11</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">3</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">4</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://encrypted-tbn3.gstatic.com/images?q=tbn:ANd9GcRhgfFsJpHeDrIFa_fRqFkKCURen03oJEh7TF5zqiXknM_gVPa1')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">L's Blog</a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">初识DDPM 算法理解（例会版）</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2023-11-08T16:00:00.000Z" title="Created 2023-11-09 00:00:00">2023-11-09</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2023-11-10T05:33:34.181Z" title="Updated 2023-11-10 13:33:34">2023-11-10</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="初识DDPM 算法理解（例会版）"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post View:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h2 id="DDPM-概率扩散模型"><a href="#DDPM-概率扩散模型" class="headerlink" title="DDPM  概率扩散模型"></a>DDPM  概率扩散模型</h2><h2 id="1-前提引入："><a href="#1-前提引入：" class="headerlink" title="1. 前提引入："></a>1. 前提引入：</h2><h3 id="1-1正态分布"><a href="#1-1正态分布" class="headerlink" title="1.1正态分布"></a>1.1正态分布</h3><p>正态分布是非常常见的连续几率随机分布。</p>
<p>对于一个骰子 假如我们随机掷骰子，随着次数的增多 每个点数出现的概率：</p>
<p><img src="https://blog-1314366587.cos.ap-nanjing.myqcloud.com/blog/DDPM/image-20231109131200020.png" style="zoom:80%;" /></p>
<p>继续增加骰子，重复这个实验：</p>
<p><img src="https://blog-1314366587.cos.ap-nanjing.myqcloud.com/blog/DDPM/image-20231109131250896.png" style="zoom:80%;" /></p>
<p><em>发现随着采样次数的增加 七点的值会逐渐增加成为一个折线</em></p>
<p>假设我们继续增加骰子，重复这个实验：</p>
<p><img src="https://blog-1314366587.cos.ap-nanjing.myqcloud.com/blog/DDPM/image-20231109131439500.png" style="zoom:80%;" /></p>
<p><em>随着骰子数量的增多，折线越来越接近这样一个曲线</em> 即为概率密度曲线</p>
<p>这样的概率分布在自然界中十分常见   即为Normal Distribution  正态分布</p>
<p>若<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/隨機變數">随机变数</a><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/68baa052181f707c662844a465bfeeb135e82bab" alt="X">服从一个<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/平均数">平均数</a>为<img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/9fd47b2a39f7a7856952afec1f1db72c67af6161" alt="\mu ">、<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/标准差">标准差</a>为<img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/59f59b7c3e6fdb1d0365a494b81fb9a696138c36" alt="\sigma ">的常态分布，则记为：<img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/2d941a7a56caf1f30802497907657ab6213f539d" alt="X \sim N(\mu,\sigma^2),"></p>
<p>则其<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/機率密度函數">概率密度函数</a>为 <img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/6fa0f3778df769845a3862bd22921041c18dd79a" alt="{\displaystyle f(x)={\frac {1}{\sigma {\sqrt {2\pi }}}}\;e^{-{\frac {\left(x-\mu \right)^{2}}{2\sigma ^{2}}}}\!}"></p>
<p>μ为平均值，σ为标准差</p>
<h3 id="1-2-扩散"><a href="#1-2-扩散" class="headerlink" title="1.2 扩散"></a>1.2 扩散</h3><p><img src="https://pic1.zhimg.com/50/v2-fbd4c82786c669575f3f31d74f67dc1c_720w.jpg?source=1940ef5c" alt="扩散现象说明分子间存在斥力为什么是错的？ - kBlnW 的回答- 知乎" style="zoom:80%;" /></p>
<p>扩散现象是自然界中很常见的一种现象 扩散现象（diffusion）是指<strong>物质分子从高浓度区域向低浓度区域转移直到均匀分布的现象</strong></p>
<p><img src="http://yang-song.net/assets/img/score/duoduo.jpg" alt="img"></p>
<p>对于一张图片 我们是否可以有 <strong>通过对图片不断增加高斯噪声来模拟这个现象，并通过你想过程从随机噪声中生成图片</strong>？</p>
<h2 id="2-DDPM"><a href="#2-DDPM" class="headerlink" title="2. DDPM:"></a>2. DDPM:</h2><h3 id="2-1-前向过程："><a href="#2-1-前向过程：" class="headerlink" title="2.1 前向过程："></a>2.1 前向过程：</h3><p><em>前向过程即为对图片添加噪声的过程</em>  那么我们怎么对一个图片添加高斯噪声呢？</p>
<p>相信学过深度学习的同学都知道  ，在处理图片数据集时  我们常采用处理图片数据的手段 <strong>对RGB通道 [x,y,z]进行归一化处理 然后做为维度特征 </strong>   加入对一张图片来讲：</p>
<p><img src="https://encrypted-tbn3.gstatic.com/images?q=tbn:ANd9GcRhgfFsJpHeDrIFa_fRqFkKCURen03oJEh7TF5zqiXknM_gVPa1" alt="img"></p>
<p>​                                                                              (●’◡’●)</p>
<p>取其中的一个像素点： </p>
<p><img src="https://blog-1314366587.cos.ap-nanjing.myqcloud.com/blog%2FDDPM%2Fimage-20231109133712273.png" alt=""></p>
<p> 我们先将像素点的数值通过归一化 压缩到[-1.0,+1.0]区间<img src="https://blog-1314366587.cos.ap-nanjing.myqcloud.com/blog%2FDDPM%2Fimage-20231109133902018.png" alt=""> <img src="https://blog-1314366587.cos.ap-nanjing.myqcloud.com/blog%2FDDPM%2Fimage-20231109133915456.png" alt=""></p>
<p>接下来我们来产生一个同样大小的噪声图片  对于每个像素点来说  我们通过高斯分布采样 对每个位置的值随机取样 所有像素通道数值遵从正态随机分布</p>
<p>接下来我们对噪声图片 和同尺寸需要加噪的进行混合  我们讲同一像素通道内数值 通过</p>
<script type="math/tex; mode=display">
\sqrt[]β×ε＋\sqrt[][1-β]×X</script><p><img src="https://blog-1314366587.cos.ap-nanjing.myqcloud.com/blog%2FDDPM%2Fimage-20231109135733072.png" style="zoom:67%;" /></p>
<p><em>β∈[0,1]  观察该公式的两个系数可知，系数平方和刚好等于一，满足勾股定理 那么对于随着β的增加 x的占比会不断减小，两者之间是此消彼长的关系</em></p>
<p>这里演示图<br>那么我们现在得到了 如何对一个图片添加高斯噪音的方法了  </p>
<p><img src="https://blog-1314366587.cos.ap-nanjing.myqcloud.com/blog%2FDDPM%2Fimage-20231109140826245.png" alt=""></p>
<p>对于这张图片       x0                       x1                      x2                       x3                      x4                       x5                      x6                        x7</p>
<script type="math/tex; mode=display">
X_1 = \sqrt[]\beta_1 \times \epsilon_1 +\sqrt{1-\beta_1}\times x_0 \\
X_2 = \sqrt[]\beta_2 \times \epsilon_2 +\sqrt{1-\beta_2}\times x_1 \\
X_3 = \sqrt[]\beta_3 \times \epsilon_3 +\sqrt{1-\beta_3}\times x_2 \\</script><p>以此类推  使用此公式不断迭代直到<script type="math/tex">x_t</script>  , 我们可以用一个式子 来表达前一时刻和后一时刻的关系 </p>
<script type="math/tex; mode=display">X_t = \sqrt[]\beta_t \times \epsilon_t+\sqrt{1-\beta_t}\times x_{t-1} \\</script><p>每一步中加噪用到的 <script type="math/tex">\epsilon \backsim N(0,1)</script>     基于标准正态分布重新采样的随机数   每一步中的<script type="math/tex">\beta</script>并不相同  ，随着时间的增加 β是逐渐趋于1的 因为扩散速度越来越快</p>
<p>为了便于 推导  我们假设<script type="math/tex">\alpha_t = 1-\beta_t</script>   那么公式就转换为了 ：</p>
<script type="math/tex; mode=display">X_t = \sqrt{1-\alpha_t} \times \epsilon_t+\sqrt{\alpha_t}\times x_{t-1}</script><p>问题：能不能直接从x0推导出xt 之间的关系呢？</p>
<p><img src="https://blog-1314366587.cos.ap-nanjing.myqcloud.com/blog/DDPM/6B7CA97F085702AAD6FDACAE58794DDC.png?q-sign-algorithm=sha1&q-ak=AKIDOV0ZvRw4ev4oSYr5WEN5KrR_mhGdYcxD3zDEvcpSiGXtO7CCCzDvKwXLiSjxnKkr&q-sign-time=1699590730;1699594330&q-key-time=1699590730;1699594330&q-header-list=host&q-url-param-list=ci-process&q-signature=bdc2c126092f5c9ebd69c210ebbd05ef045215e3&x-cos-security-token=mOQNthc5lplJwEloGj6oXYh0zlRn5CJad7d5e98b51ccd9adcf2c65e50125cddc4yaCz-fRYy0N_B1TvIfRQP95OWJCStDG0wDXQI9A0PJ1jzbMXXGhfyAXBiZD6epu1nJbiPyCNVV0ViHMYUr1uVL5b2EOq7T4Ls0yWaB6zkjrgVH_aj0Ej-OBhkDhOvicRQUxqMYrERthz98EGYrpW2tgVFNcmOMl8x7HlhCcI6MzC52hi4NA7Soz2J7d9k4g&ci-process=originImage" style="zoom: 33%;" /></p>
<p>现在得到了Xt和Xt-2的关系  对于参数<script type="math/tex">\epsilon</script>  他是从正态随机分布采样出来的值   那么如前提所知  两个骰子的概率分布叠加后满足正态分布 ，</p>
<p>那么我们可不可以知道多种采样的的概率叠加呢</p>
<p>  <img src="http://yang-song.net/assets/img/score/ebm.gif" alt="img"><img src="https://img-blog.csdnimg.cn/20200625195851934.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2NoYW9zaXIxOTkx,size_16,color_FFFFFF,t_70" alt="两个高斯分布相加（卷积）的理论推导-CSDN博客" style="zoom:50%;" /></p>
<p>现对于两个正态分布的卷积依然是正态分布</p>
<p>那么对于上述式子 我们可以把 两次随机分布采样变为一次随机分布采样</p>
<p>分析上面的式子</p>
<p><img src="https://blog-1314366587.cos.ap-nanjing.myqcloud.com/blog%2FDDPM%2Fimage-20231109145549798.png" alt=""></p>
<p>对于正态分布N(0,1)  如果乘一个常数m 那么平均值变为mμ，标准差变为mσ</p>
<p>根据定义我们可以很快的知道 对于一个叠加的正态分布 我们有</p>
<script type="math/tex; mode=display">N(\mu_1,\sigma_1^2) + N(\mu_2,\sigma_2^2)=N(\mu_1+\mu_2,\sigma_1^2+\sigma_2^2)</script><p>我们可以得出<script type="math/tex">N(0,\alpha_t-\alpha_t\alpha_{t-1}),N(0,1-\alpha_t)</script>是属于刚刚上面两个采样的分布的</p>
<p>那么他俩的叠加后的分布 根据公式可得  <script type="math/tex">N(0,\alpha_t-\alpha_t\alpha_{t-1}) +N(0,1-\alpha_t) = N(0,1-\alpha_t\alpha_{t-1})</script></p>
<p>那么我们的Xt的公式可以改写为：</p>
<script type="math/tex; mode=display">X_t = \sqrt{1-\alpha_t\alpha_{t-1}}\epsilon+\sqrt{\alpha_t\alpha_{t-1}}X_{t-1}</script><p>这种技巧叫做重参数化技巧</p>
<p>那么我可以递推出xt和xt-2之间的关系   ……..  </p>
<p>通过数学归纳法 我们可以得出  </p>
<p><img src="https://blog-1314366587.cos.ap-nanjing.myqcloud.com/blog/DDPM/9FEFB2ABF792AB133E139524691C9A24.png?q-sign-algorithm=sha1&q-ak=AKIDnxL6LVTJBnUlNXnCUagKGUg8CdKFktVxR35hWaFDtUEt8RxhrdruOn-7m7iddOSy&q-sign-time=1699590851;1699594451&q-key-time=1699590851;1699594451&q-header-list=host&q-url-param-list=ci-process&q-signature=698f53879d3b14a969782b0cc639f582cd920d40&x-cos-security-token=B80XrI59VOTlXumQ1kq5eftQo3A9xvua85050068758525aa5f6998e190c85e16BF6FVkEVKiNVBubGA207yJv8eLMeq4HOEKclOENV3aQ0bnNUVb6cuROJ_O4Nqn7UcjXpdQ_HtruiLZmtX585N7NZFvv5vuPVjQqE7o2q6d7w8Hzul0aqOJVGNEYbVYqTdUpLWo3p0Ls5YJLE1VAP8B7QadC_4l5XiHn-Ei8WZMOF77Msa9V5x668v2-puTgC&ci-process=originImage" style="zoom:50%;" /></p>
<p>这样我们就得到了Xt和X0的关系了</p>
<p>为了简化 方便描述 我们设<script type="math/tex">\bar \alpha = \alpha_t\alpha_{t-1}....\alpha_1</script></p>
<p>很好 我们现在得出:</p>
<script type="math/tex; mode=display">X_t = \sqrt{1-\bar\alpha}\epsilon+ \sqrt {\bar\alpha}X_0,\epsilon \backsim N(0,1)</script><script type="math/tex; mode=display">q(x_{t}|x_{0}) = \frac{1}{\sqrt{2\pi } \sqrt{1-\bar{a}*{t}}} e^{\left ( -\frac{1}{2}\frac{(x*{t}-\sqrt{\bar{a}*{t}}x_0)^2}{1-\bar{a}*{t}} \right ) }</script><h3 id="2-2-反向推理"><a href="#2-2-反向推理" class="headerlink" title="2.2 反向推理"></a>2.2 反向推理</h3><p>通过刚刚的推导 我们理解了 在前向加噪的过程中发生的变化  </p>
<p><img src="C:\Users\86198\AppData\Roaming\Typora\typora-user-images\image-20231109153836778.png" alt="image-20231109153836778"></p>
<p>那么我们的目的是反向去噪生成模型  这个怎么实现呢？</p>
<p>我们可以用此关系 反向推理求出和X0的关系</p>
<p>知识点 ：贝叶斯定理</p>
<p><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/e08d4ab0386c0ebb7d87f398cd38f911440fe3da" alt="{\displaystyle P(A\mid B)={\frac {P(A)P(B\mid A)}{P(B)}}}"></p>
<p>我们的目标是<script type="math/tex">X_t = \sqrt{1-\bar\alpha}\epsilon_t+ \sqrt {\bar\alpha}X_{t-1}</script></p>
<p>那么对于后验概率<script type="math/tex">p(X_{t-1}|X_t)=\cfrac{p(X_t|X_{t-1})p(X_{t-1})}{p(X_t)}</script></p>
<p>分别为<script type="math/tex">X_t,X_{t-1}</script>时刻的概率  也就是从X0推断出的概率</p>
<p>所以 我们 可以用另外一个形式来表示</p>
<script type="math/tex; mode=display">
p(X_{t-1}|X_t,X_0)=\cfrac{p(X_t|X_{t-1},X_0)p(X_{t-1}|X_0)}{p(X_t|X_0)}</script><p> 至此 只要求解右边的式子 我们就可以知道给定Xt时刻,前一时刻<script type="math/tex">X_{t-1}</script>的概率</p>
<script type="math/tex; mode=display">x_{t} = \sqrt{a_t}x_{t-1}+\sqrt{1-a_t}\times ϵ$$ ~ $N(\sqrt{a_t}x_{t-1}, 1-a_{t})$

$$x_{t-1} = \sqrt{\bar{a}_{t-1}}x_0+ \sqrt{1-\bar{a}_{t-1}}\times ϵ$$ ~  $N( \sqrt{\bar{a}_{t-1}}x_0, 1-\bar{a}_{t-1})$

  $$x_{t} = \sqrt{\bar{a}_{t}}x_0+ \sqrt{1-\bar{a}_{t}}\times ϵ$$ ~   $N( \sqrt{\bar{a}_{t}}x_0, 1-\bar{a}_{t})$

**既然我们已知了不同阶段的正态分布函数，通过概率密度函数 我们可以求出该时刻的概率  将三者概率带入到我们的朴素贝叶斯公式中可以得出**

$$ q(x_{t}|x_{t-1},x_{0}) = \frac{1}{\sqrt{2\pi } \sqrt{1-a_{t}}} e^{\left (  -\frac{1}{2}\frac{(x_{t}-\sqrt{a_t}x_{t-1})^2}{1-a_{t}}   \right ) }</script><p>推导过程如下：</p>
<script type="math/tex; mode=display">\frac{ q(x_{t}|x_{t-1},x_{0})\times q(x_{t-1}|x_0)}{q(x_{t}|x_0)} = \left [
  \frac{1}{\sqrt{2\pi} \sqrt{1-a_{t}}} e^{\left (  -\frac{1}{2}\frac{(x_{t}-\sqrt{a_t}x_{t-1})^2}{1-a_{t}}   \right ) } 
\right ] * 
\left [ 
\frac{1}{\sqrt{2\pi} \sqrt{1-\bar{a}_{t-1}}} e^{\left (  -\frac{1}{2}\frac{(x_{t-1}-\sqrt{\bar{a}_{t-1}}x_0)^2}{1-\bar{a}_{t-1}}   \right ) }  
\right ] \div
\left [ 
  \frac{1}{\sqrt{2\pi} \sqrt{1-\bar{a}_{t}}} e^{\left (  -\frac{1}{2}\frac{(x_{t}-\sqrt{\bar{a}_{t}}x_0)^2}{1-\bar{a}_{t}}   \right ) }
\right ]</script><script type="math/tex; mode=display">\Downarrow</script><script type="math/tex; mode=display">\frac{\sqrt{2\pi} \sqrt{1-\bar{a}_{t}}}{\sqrt{2\pi} \sqrt{1-a_{t}} \sqrt{2\pi} \sqrt{1-\bar{a}_{t-1}} }
e^{\left [  -\frac{1}{2}
\left (
 \frac{(x_{t}-\sqrt{a_t}x_{t-1})^2}{1-a_{t}} +
 \frac{(x_{t-1}-\sqrt{\bar{a}_{t-1}}x_0)^2}{1-\bar{a}_{t-1}} -
 \frac{(x_{t}-\sqrt{\bar{a}_{t}}x_0)^2}{1-\bar{a}_{t}}
 \right )
    \right ] }</script><script type="math/tex; mode=display">\Downarrow</script><script type="math/tex; mode=display">\frac{1}{\sqrt{2\pi} \left ( \frac{ \sqrt{1-a_t} \sqrt{1-\bar{a}_{t-1}} } {\sqrt{1-\bar{a}_{t}}} \right ) }
exp{\left [  -\frac{1}{2}
\left (
 \frac{(x_{t}-\sqrt{a_t}x_{t-1})^2}{1-a_t} +
 \frac{(x_{t-1}-\sqrt{\bar{a}_{t-1}}x_0)^2}{1-\bar{a}_{t-1}} -
 \frac{(x_{t}-\sqrt{\bar{a}_{t}}x_0)^2}{1-\bar{a}_{t}}
 \right )
    \right ] }</script><script type="math/tex; mode=display">\Downarrow</script><script type="math/tex; mode=display">\frac{1}{\sqrt{2\pi} \left ( \frac{ \sqrt{1-a_t} \sqrt{1-\bar{a}_{t-1}} } {\sqrt{1-\bar{a}_{t}}} \right ) }
exp \left[  -\frac{1}{2}
\left (
 \frac{
   x_{t}^2-2\sqrt{a_t}x_{t}x_{t-1}+{a_t}x_{t-1}^2
 }{1-a_t} +
 \frac{
   x_{t-1}^2-2\sqrt{\bar{a}_{t-1}}x_0x_{t-1}+\bar{a}_{t-1}x_0^2
  }{1-\bar{a}_{t-1}} -
 \frac{(x_{t}-\sqrt{\bar{a}_{t}}x_0)^2}{1-\bar{a}_{t}}
\right)
\right]</script><script type="math/tex; mode=display">\Downarrow</script><script type="math/tex; mode=display">\frac{1}{\sqrt{2\pi} \left ( {\color{Red} \frac{ \sqrt{1-a_t} \sqrt{1-\bar{a}_{t-1}} } {\sqrt{1-\bar{a}_{t}}}}  \right ) }  
exp \left[
-\frac{1}{2}
\frac{
  \left(
    x_{t-1} - \left(
      {\color{Purple} \frac{\sqrt{a_t}(1-\bar{a}_{t-1})}{1-\bar{a}_t}x_t
      +
      \frac{\sqrt{\bar{a}_{t-1}}(1-a_t)}{1-\bar{a}_t}x_0} 
      \right)
  \right) ^2
} {   \left( {\color{Red} \frac{ \sqrt{1-a_t} \sqrt{1-\bar{a}_{t-1}} } {\sqrt{1-\bar{a}_{t}}}}  \right)^2 }
\right]</script><script type="math/tex; mode=display">\Downarrow</script><script type="math/tex; mode=display">p(x_{t-1}|x_{t}) \sim N\left( 
      {\color{Purple} \frac{\sqrt{a_t}(1-\bar{a}_{t-1})}{1-\bar{a}_t}x_t
      +
      \frac{\sqrt{\bar{a}_{t-1}}(1-a_t)}{1-\bar{a}_t}x_0}  ,
      \left( {\color{Red} \frac{ \sqrt{1-a_t} \sqrt{1-\bar{a}_{t-1}} } {\sqrt{1-\bar{a}_{t}}}}  \right)^2
 \right)</script><p>求得反向推导的函数公式为</p>
<p>又因为 $x_{t} = \sqrt{\bar{a}_t}\times x_0+ \sqrt{1-\bar{a}_t}\times ϵ$, $x_0 = \frac{x_t - \sqrt{1-\bar{a}_t}\times ϵ}{\sqrt{\bar{a}_t}}$. 代换如上述函数可得</p>
<script type="math/tex; mode=display">p(x_{t-1}|x_{t}) \sim N\left( 
      {\color{Purple} \frac{\sqrt{a_t}(1-\bar{a}_{t-1})}{1-\bar{a}_t}x_t
      +
      \frac{\sqrt{\bar{a}_{t-1}}(1-a_t)}{1-\bar{a}_t}\times \frac{x_t - \sqrt{1-\bar{a}_t}\times ϵ}{\sqrt{\bar{a}_t}} } ,
       {\color{Red} \frac{ \beta_{t} (1-\bar{a}_{t-1}) } { 1-\bar{a}_{t}}} 
 \right)</script><p>由此 我们知道  怎么通过概率反向推出原图片的过程</p>
<h3 id="3-3-代码实现"><a href="#3-3-代码实现" class="headerlink" title="3.3 代码实现"></a>3.3 代码实现</h3><p>通过上述的问题 我们可以了解到 DDPM模型 在神经网络中的结构  </p>
<p>详细见<a target="_blank" rel="noopener" href="https://colab.research.google.com/drive/1WQ0fZL199I4LjnfNL_Kgma5rznR7rJW0#scrollTo=4PFEXUY8J2Fe">colab DF</a></p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="https://kidoom.github.io">kidoom</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="https://kidoom.github.io/2023/11/09/DDPM%20%E4%BE%8B%E4%BC%9A%E7%89%88/">https://kidoom.github.io/2023/11/09/DDPM%20%E4%BE%8B%E4%BC%9A%E7%89%88/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"><div class="social-share" data-image="https://encrypted-tbn3.gstatic.com/images?q=tbn:ANd9GcRhgfFsJpHeDrIFa_fRqFkKCURen03oJEh7TF5zqiXknM_gVPa1" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2023/11/14/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%BB%AA%E8%AE%BA/"><img class="prev-cover" src="https://blog-1314366587.cos.ap-nanjing.myqcloud.com/blog%2Fml%2Fimage-20231114214444065.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">Previous Post</div><div class="prev_info">机器学习绪论</div></div></a></div><div class="next-post pull-right"><a href="/2023/11/09/Probabilistic%20Diffusion%20Model%E6%A6%82%E7%8E%87%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%8C%E6%95%B4PyTorch%E4%BB%A3%E7%A0%81%E8%AF%A6%E7%BB%86%E8%A7%A3%E8%AF%BB/"><img class="next-cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">Next Post</div><div class="next_info">Probabilistic Diffusion Model概率扩散模型理论与完整PyTorch代码详细解读</div></div></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://blog-1314366587.cos.ap-nanjing.myqcloud.com/blog%2FDTicon.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">kidoom</div><div class="author-info__description"></div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">11</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">3</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">4</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/kidoom"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/kidoom?tab=repositories" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:3416888646@qq.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>Announcement</span></div><div class="announcement_content">记录学习历程</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Catalog</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#DDPM-%E6%A6%82%E7%8E%87%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B"><span class="toc-number">1.</span> <span class="toc-text">DDPM  概率扩散模型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%E5%89%8D%E6%8F%90%E5%BC%95%E5%85%A5%EF%BC%9A"><span class="toc-number">2.</span> <span class="toc-text">1. 前提引入：</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-1%E6%AD%A3%E6%80%81%E5%88%86%E5%B8%83"><span class="toc-number">2.1.</span> <span class="toc-text">1.1正态分布</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-2-%E6%89%A9%E6%95%A3"><span class="toc-number">2.2.</span> <span class="toc-text">1.2 扩散</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-DDPM"><span class="toc-number">3.</span> <span class="toc-text">2. DDPM:</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-%E5%89%8D%E5%90%91%E8%BF%87%E7%A8%8B%EF%BC%9A"><span class="toc-number">3.1.</span> <span class="toc-text">2.1 前向过程：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-%E5%8F%8D%E5%90%91%E6%8E%A8%E7%90%86"><span class="toc-number">3.2.</span> <span class="toc-text">2.2 反向推理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-3-%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0"><span class="toc-number">3.3.</span> <span class="toc-text">3.3 代码实现</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2023/11/14/%5B%E5%A4%A9%E6%B1%A0%5D%E5%85%A8%E7%90%83%E6%99%BA%E8%83%BD%E6%B1%BD%E8%BD%A6AI%E6%8C%91%E6%88%98%E8%B5%9B/" title="天池全球智能汽车AI挑战赛实践"><img src="https://blog-1314366587.cos.ap-nanjing.myqcloud.com/blog%2Fdf%20huggingface%2Fimage-20231107205013285.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="天池全球智能汽车AI挑战赛实践"/></a><div class="content"><a class="title" href="/2023/11/14/%5B%E5%A4%A9%E6%B1%A0%5D%E5%85%A8%E7%90%83%E6%99%BA%E8%83%BD%E6%B1%BD%E8%BD%A6AI%E6%8C%91%E6%88%98%E8%B5%9B/" title="天池全球智能汽车AI挑战赛实践">天池全球智能汽车AI挑战赛实践</a><time datetime="2023-11-13T16:00:00.000Z" title="Created 2023-11-14 00:00:00">2023-11-14</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/11/14/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%BB%AA%E8%AE%BA/" title="机器学习绪论"><img src="https://blog-1314366587.cos.ap-nanjing.myqcloud.com/blog%2Fml%2Fimage-20231114214444065.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="机器学习绪论"/></a><div class="content"><a class="title" href="/2023/11/14/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%BB%AA%E8%AE%BA/" title="机器学习绪论">机器学习绪论</a><time datetime="2023-11-13T16:00:00.000Z" title="Created 2023-11-14 00:00:00">2023-11-14</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/11/09/DDPM%20%E4%BE%8B%E4%BC%9A%E7%89%88/" title="初识DDPM 算法理解（例会版）"><img src="https://encrypted-tbn3.gstatic.com/images?q=tbn:ANd9GcRhgfFsJpHeDrIFa_fRqFkKCURen03oJEh7TF5zqiXknM_gVPa1" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="初识DDPM 算法理解（例会版）"/></a><div class="content"><a class="title" href="/2023/11/09/DDPM%20%E4%BE%8B%E4%BC%9A%E7%89%88/" title="初识DDPM 算法理解（例会版）">初识DDPM 算法理解（例会版）</a><time datetime="2023-11-08T16:00:00.000Z" title="Created 2023-11-09 00:00:00">2023-11-09</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/11/09/Probabilistic%20Diffusion%20Model%E6%A6%82%E7%8E%87%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%8C%E6%95%B4PyTorch%E4%BB%A3%E7%A0%81%E8%AF%A6%E7%BB%86%E8%A7%A3%E8%AF%BB/" title="Probabilistic Diffusion Model概率扩散模型理论与完整PyTorch代码详细解读"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Probabilistic Diffusion Model概率扩散模型理论与完整PyTorch代码详细解读"/></a><div class="content"><a class="title" href="/2023/11/09/Probabilistic%20Diffusion%20Model%E6%A6%82%E7%8E%87%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%8C%E6%95%B4PyTorch%E4%BB%A3%E7%A0%81%E8%AF%A6%E7%BB%86%E8%A7%A3%E8%AF%BB/" title="Probabilistic Diffusion Model概率扩散模型理论与完整PyTorch代码详细解读">Probabilistic Diffusion Model概率扩散模型理论与完整PyTorch代码详细解读</a><time datetime="2023-11-08T16:00:00.000Z" title="Created 2023-11-09 00:00:00">2023-11-09</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/11/09/diffusion_model/" title="Diffusion_model 应用（Huggingface）"><img src="https://blog-1314366587.cos.ap-nanjing.myqcloud.com/blog%2Fdf%20huggingface%2Fimage-20231107205013285.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Diffusion_model 应用（Huggingface）"/></a><div class="content"><a class="title" href="/2023/11/09/diffusion_model/" title="Diffusion_model 应用（Huggingface）">Diffusion_model 应用（Huggingface）</a><time datetime="2023-11-08T16:00:00.000Z" title="Created 2023-11-09 00:00:00">2023-11-09</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2023 By kidoom</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Switch Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle between single-column and double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="Back To Top"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><script>var preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',preloader.endLoading())</script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    chtml: {
      scale: 1.2
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        insertScript: [200, () => {
          document.querySelectorAll('mjx-container:not\([display]\)').forEach(node => {
            const target = node.parentNode
            if (target.nodeName.toLowerCase() === 'li') {
              target.parentNode.classList.add('has-jax')
            } else {
              target.classList.add('has-jax')
            }
          });
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typeset()
}</script></div><script id="canvas_nest" defer="defer" color="0,0,0" opacity="0.7" zIndex="-1" count="99" mobile="true" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-nest.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>