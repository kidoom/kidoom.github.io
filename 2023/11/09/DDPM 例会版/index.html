<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>L's Blog | L's Blog</title><meta name="author" content="kidoom"><meta name="copyright" content="kidoom"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="DDPM  概率扩散模型1. 前提引入：1.1正态分布正态分布是非常常见的连续几率随机分布。 对于一个骰子 假如我们随机掷骰子，随着次数的增多 每个点数出现的概率：   继续增加骰子，重复这个实验：   发现随着采样次数的增加 七点的值会逐渐增加成为一个折线 假设我们继续增加骰子，重复这个实验：   随着骰子数量的增多，折线越来越接近这样一个曲线 即为概率密度曲线 这样的概率分布在自然界中十分常见">
<meta property="og:type" content="article">
<meta property="og:title" content="L&#39;s Blog">
<meta property="og:url" content="https://kidoom.github.io/2023/11/09/DDPM%20%E4%BE%8B%E4%BC%9A%E7%89%88/index.html">
<meta property="og:site_name" content="L&#39;s Blog">
<meta property="og:description" content="DDPM  概率扩散模型1. 前提引入：1.1正态分布正态分布是非常常见的连续几率随机分布。 对于一个骰子 假如我们随机掷骰子，随着次数的增多 每个点数出现的概率：   继续增加骰子，重复这个实验：   发现随着采样次数的增加 七点的值会逐渐增加成为一个折线 假设我们继续增加骰子，重复这个实验：   随着骰子数量的增多，折线越来越接近这样一个曲线 即为概率密度曲线 这样的概率分布在自然界中十分常见">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2023-11-09T05:03:19.156Z">
<meta property="article:modified_time" content="2023-11-10T04:35:18.870Z">
<meta property="article:author" content="kidoom">
<meta name="twitter:card" content="summary"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://kidoom.github.io/2023/11/09/DDPM%20%E4%BE%8B%E4%BC%9A%E7%89%88/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: 'Just',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: [object Object]
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'L\'s Blog',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-11-10 12:35:18'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.3.0"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">Loading...</div></div></div><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://s1.328888.xyz/2022/10/08/fWUT0.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">8</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">0</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">0</div></a></div><hr/></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">L's Blog</a></span><div id="menus"><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">No title</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2023-11-09T05:03:19.156Z" title="Created 2023-11-09 13:03:19">2023-11-09</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2023-11-10T04:35:18.870Z" title="Updated 2023-11-10 12:35:18">2023-11-10</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post View:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h2 id="DDPM-概率扩散模型"><a href="#DDPM-概率扩散模型" class="headerlink" title="DDPM  概率扩散模型"></a>DDPM  概率扩散模型</h2><h2 id="1-前提引入："><a href="#1-前提引入：" class="headerlink" title="1. 前提引入："></a>1. 前提引入：</h2><h3 id="1-1正态分布"><a href="#1-1正态分布" class="headerlink" title="1.1正态分布"></a>1.1正态分布</h3><p>正态分布是非常常见的连续几率随机分布。</p>
<p>对于一个骰子 假如我们随机掷骰子，随着次数的增多 每个点数出现的概率：</p>
<img src="https://blog-1314366587.cos.ap-nanjing.myqcloud.com/blog/DDPM/image-20231109131200020.png?q-sign-algorithm=sha1&q-ak=AKIDQ7Tsv5EFQn00V-kngcdaoTCQpPQbKiuKdYcn5joxf_v4UYUEyvi612Xr3VpDCqFj&q-sign-time=1699590228;1699593828&q-key-time=1699590228;1699593828&q-header-list=host&q-url-param-list=ci-process&q-signature=db646b0ab8521ed4a4aa72eb63a09d7fdcb5f7a1&x-cos-security-token=mOQNthc5lplJwEloGj6oXYh0zlRn5CJaac41e3eeb94c6eeecf073a0a4eda698c4yaCz-fRYy0N_B1TvIfRQCNIKEPMB66gxMKMAgnv5nUL8zVZM7n89koDaMBTQByvvcxSEtwvVsu9B0Z2Dw7Zd911foYV9TvzU0ygSDVuMz2oNmgP2h2PCKN1XyNDYcLY9wJXpgcMOthUVzyvzgKf66u2QCJvtXozw6hnUj8oUcLAR2t-t4jwFKQ9dJX-COXc&ci-process=originImage" style="zoom:80%;" />

<p>继续增加骰子，重复这个实验：</p>
<img src="https://blog-1314366587.cos.ap-nanjing.myqcloud.com/blog/DDPM/image-20231109131250896.png?q-sign-algorithm=sha1&q-ak=AKIDV-YvOh6mRdT_mbpuUhXEG-YhYpaBIOW4rqCpEv3SvLNvP06iVOVZhaBbr3CFuo9H&q-sign-time=1699590270;1699593870&q-key-time=1699590270;1699593870&q-header-list=host&q-url-param-list=ci-process&q-signature=dd6a6abcbdba3c19bc21ec773230c23930047ea6&x-cos-security-token=mOQNthc5lplJwEloGj6oXYh0zlRn5CJadff2374b0554541c8018cd7da46ff3a04yaCz-fRYy0N_B1TvIfRQDgPQJ5Up9m6Iml7XV4XBe8gh7DQX7ZLN0WatTIien3mBG_xXxxcPwqR5DGwZokvXFoUytQa_wnEtc4a2iSelUZXkA1k2LmHpIGdQ1Qturzr78tANjzfqWc-Or1DJyyPFaw02L6avzuURGUvwRMhBbwchCtUkdpPZjFtYFByy_zb&ci-process=originImage" style="zoom:80%;" />

<p><em>发现随着采样次数的增加 七点的值会逐渐增加成为一个折线</em></p>
<p>假设我们继续增加骰子，重复这个实验：</p>
<img src="https://blog-1314366587.cos.ap-nanjing.myqcloud.com/blog/DDPM/image-20231109131439500.png?q-sign-algorithm=sha1&q-ak=AKID7QUjFyLx4ok52cxCYGmkWzYhdylZtVBmu-zqrm3LRzox_6OkzFQPfQmNAaFFhMGO&q-sign-time=1699590291;1699593891&q-key-time=1699590291;1699593891&q-header-list=host&q-url-param-list=ci-process&q-signature=49159510002a2f9aa75d5122579fca85adb0b48f&x-cos-security-token=B80XrI59VOTlXumQ1kq5eftQo3A9xvua570c5f816905aab38c7c63248c114bffBF6FVkEVKiNVBubGA207yMZF-9dYJ8E-cu93Wonj-l1u9zScUo0oqHY4Y0VaEkbvQIkZE1_Q3ELFU1gBhRKXoX2WOinM8XwkxX-XtJTOcE6lyYCzqzxFY9Gwpehl3u2CIdPOk7e2AC7PYBcng2d69UgCnz9lcMzvd1bZiisfnH7-ntXkaHVmiQj86eRzDr82&ci-process=originImage" style="zoom:80%;" />

<p><em>随着骰子数量的增多，折线越来越接近这样一个曲线</em> 即为概率密度曲线</p>
<p>这样的概率分布在自然界中十分常见   即为Normal Distribution  正态分布</p>
<p>若<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E9%9A%A8%E6%A9%9F%E8%AE%8A%E6%95%B8">随机变数</a><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/68baa052181f707c662844a465bfeeb135e82bab" alt="X">服从一个<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E5%B9%B3%E5%9D%87%E6%95%B0">平均数</a>为<img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/9fd47b2a39f7a7856952afec1f1db72c67af6161" alt="\mu ">、<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E6%A0%87%E5%87%86%E5%B7%AE">标准差</a>为<img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/59f59b7c3e6fdb1d0365a494b81fb9a696138c36" alt="\sigma ">的常态分布，则记为：<img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/2d941a7a56caf1f30802497907657ab6213f539d" alt="X \sim N(\mu,\sigma^2),"></p>
<p>则其<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E6%A9%9F%E7%8E%87%E5%AF%86%E5%BA%A6%E5%87%BD%E6%95%B8">概率密度函数</a>为 <img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/6fa0f3778df769845a3862bd22921041c18dd79a" alt="{\displaystyle f(x)={\frac {1}{\sigma {\sqrt {2\pi }}}}\;e^{-{\frac {\left(x-\mu \right)^{2}}{2\sigma ^{2}}}}\!}"></p>
<p>μ为平均值，σ为标准差</p>
<h3 id="1-2-扩散"><a href="#1-2-扩散" class="headerlink" title="1.2 扩散"></a>1.2 扩散</h3><img src="https://pic1.zhimg.com/50/v2-fbd4c82786c669575f3f31d74f67dc1c_720w.jpg?source=1940ef5c" alt="扩散现象说明分子间存在斥力为什么是错的？ - kBlnW 的回答- 知乎" style="zoom:80%;" />

<p>扩散现象是自然界中很常见的一种现象 扩散现象（diffusion）是指<strong>物质分子从高浓度区域向低浓度区域转移直到均匀分布的现象</strong></p>
<p><img src="http://yang-song.net/assets/img/score/duoduo.jpg" alt="img"></p>
<p>对于一张图片 我们是否可以有 <strong>通过对图片不断增加高斯噪声来模拟这个现象，并通过你想过程从随机噪声中生成图片</strong>？</p>
<h2 id="2-DDPM"><a href="#2-DDPM" class="headerlink" title="2. DDPM:"></a>2. DDPM:</h2><h3 id="2-1-前向过程："><a href="#2-1-前向过程：" class="headerlink" title="2.1 前向过程："></a>2.1 前向过程：</h3><p><em>前向过程即为对图片添加噪声的过程</em>  那么我们怎么对一个图片添加高斯噪声呢？</p>
<p>相信学过深度学习的同学都知道  ，在处理图片数据集时  我们常采用处理图片数据的手段 **对RGB通道 [x,y,z]进行归一化处理 然后做为维度特征 **   加入对一张图片来讲：</p>
<p><img src="https://encrypted-tbn3.gstatic.com/images?q=tbn:ANd9GcRhgfFsJpHeDrIFa_fRqFkKCURen03oJEh7TF5zqiXknM_gVPa1" alt="img"></p>
<p>​													                          (●’◡’●)</p>
<p>取其中的一个像素点： </p>
<p><img src="https://blog-1314366587.cos.ap-nanjing.myqcloud.com/blog%2FDDPM%2Fimage-20231109133712273.png"></p>
<p> 我们先将像素点的数值通过归一化 压缩到[-1.0,+1.0]区间<img src="https://blog-1314366587.cos.ap-nanjing.myqcloud.com/blog%2FDDPM%2Fimage-20231109133902018.png"> <img src="https://blog-1314366587.cos.ap-nanjing.myqcloud.com/blog%2FDDPM%2Fimage-20231109133915456.png"></p>
<p>接下来我们来产生一个同样大小的噪声图片  对于每个像素点来说  我们通过高斯分布采样 对每个位置的值随机取样 所有像素通道数值遵从正态随机分布</p>
<p>接下来我们对噪声图片 和同尺寸需要加噪的进行混合  我们讲同一像素通道内数值 通过<br>$$<br>\sqrt[]β×ε＋\sqrt[][1-β]×X<br>$$<br><img src="https://blog-1314366587.cos.ap-nanjing.myqcloud.com/blog%2FDDPM%2Fimage-20231109135733072.png" style="zoom:67%;" /></p>
<p><em>β∈[0,1]  观察该公式的两个系数可知，系数平方和刚好等于一，满足勾股定理 那么对于随着β的增加 x的占比会不断减小，两者之间是此消彼长的关系</em></p>
<p>这里演示图<br>那么我们现在得到了 如何对一个图片添加高斯噪音的方法了  </p>
<p><img src="https://blog-1314366587.cos.ap-nanjing.myqcloud.com/blog%2FDDPM%2Fimage-20231109140826245.png"></p>
<p>对于这张图片       x0                       x1                      x2                       x3                      x4                       x5                      x6                        x7<br>$$<br>X_1 &#x3D; \sqrt[]\beta_1 \times \epsilon_1 +\sqrt{1-\beta_1}\times x_0 \<br>X_2 &#x3D; \sqrt[]\beta_2 \times \epsilon_2 +\sqrt{1-\beta_2}\times x_1 \<br>X_3 &#x3D; \sqrt[]\beta_3 \times \epsilon_3 +\sqrt{1-\beta_3}\times x_2 \<br>$$<br>以此类推  使用此公式不断迭代直到$$x_t$$  , 我们可以用一个式子 来表达前一时刻和后一时刻的关系<br>$$X_t &#x3D; \sqrt[]\beta_t \times \epsilon_t+\sqrt{1-\beta_t}\times x_{t-1} \$$</p>
<p>每一步中加噪用到的 $$\epsilon \backsim N(0,1)$$     基于标准正态分布重新采样的随机数   每一步中的$$\beta$$并不相同  ，随着时间的增加 β是逐渐趋于1的 因为扩散速度越来越快</p>
<p>为了便于 推导  我们假设$$\alpha_t &#x3D; 1-\beta_t$$   那么公式就转换为了 ：</p>
<p>$$X_t &#x3D; \sqrt{1-\alpha_t} \times \epsilon_t+\sqrt{\alpha_t}\times x_{t-1} $$</p>
<p>问题：能不能直接从x0推导出xt 之间的关系呢？</p>
<img src="https://blog-1314366587.cos.ap-nanjing.myqcloud.com/blog/DDPM/6B7CA97F085702AAD6FDACAE58794DDC.png?q-sign-algorithm=sha1&q-ak=AKIDOV0ZvRw4ev4oSYr5WEN5KrR_mhGdYcxD3zDEvcpSiGXtO7CCCzDvKwXLiSjxnKkr&q-sign-time=1699590730;1699594330&q-key-time=1699590730;1699594330&q-header-list=host&q-url-param-list=ci-process&q-signature=bdc2c126092f5c9ebd69c210ebbd05ef045215e3&x-cos-security-token=mOQNthc5lplJwEloGj6oXYh0zlRn5CJad7d5e98b51ccd9adcf2c65e50125cddc4yaCz-fRYy0N_B1TvIfRQP95OWJCStDG0wDXQI9A0PJ1jzbMXXGhfyAXBiZD6epu1nJbiPyCNVV0ViHMYUr1uVL5b2EOq7T4Ls0yWaB6zkjrgVH_aj0Ej-OBhkDhOvicRQUxqMYrERthz98EGYrpW2tgVFNcmOMl8x7HlhCcI6MzC52hi4NA7Soz2J7d9k4g&ci-process=originImage" style="zoom: 33%;" />

<p>现在得到了Xt和Xt-2的关系  对于参数$$\epsilon$$  他是从正态随机分布采样出来的值   那么如前提所知  两个骰子的概率分布叠加后满足正态分布 ，</p>
<p>那么我们可不可以知道多种采样的的概率叠加呢</p>
<p>  <img src="http://yang-song.net/assets/img/score/ebm.gif" alt="img"><img src="https://img-blog.csdnimg.cn/20200625195851934.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2NoYW9zaXIxOTkx,size_16,color_FFFFFF,t_70" alt="两个高斯分布相加（卷积）的理论推导-CSDN博客" style="zoom:50%;" /></p>
<p>现对于两个正态分布的卷积依然是正态分布</p>
<p>那么对于上述式子 我们可以把 两次随机分布采样变为一次随机分布采样</p>
<p>分析上面的式子</p>
<p><img src="https://blog-1314366587.cos.ap-nanjing.myqcloud.com/blog%2FDDPM%2Fimage-20231109145549798.png"></p>
<p>对于正态分布N(0,1)  如果乘一个常数m 那么平均值变为mμ，标准差变为mσ</p>
<p>根据定义我们可以很快的知道 对于一个叠加的正态分布 我们有</p>
<p>$$N(\mu_1,\sigma_1^2) + N(\mu_2,\sigma_2^2)&#x3D;N(\mu_1+\mu_2,\sigma_1^2+\sigma_2^2) $$ </p>
<p>我们可以得出$$N(0,\alpha_t-\alpha_t\alpha_{t-1}),N(0,1-\alpha_t)$$是属于刚刚上面两个采样的分布的</p>
<p>那么他俩的叠加后的分布 根据公式可得  $$N(0,\alpha_t-\alpha_t\alpha_{t-1}) +N(0,1-\alpha_t) &#x3D; N(0,1-\alpha_t\alpha_{t-1}) $$</p>
<p>那么我们的Xt的公式可以改写为：</p>
<p>$$ X_t &#x3D; \sqrt{1-\alpha_t\alpha_{t-1}}\epsilon+\sqrt{\alpha_t\alpha_{t-1}}X_{t-1}$$</p>
<p>这种技巧叫做重参数化技巧</p>
<p>那么我可以递推出xt和xt-2之间的关系   ……..  </p>
<p>通过数学归纳法 我们可以得出  </p>
<img src="https://blog-1314366587.cos.ap-nanjing.myqcloud.com/blog/DDPM/9FEFB2ABF792AB133E139524691C9A24.png?q-sign-algorithm=sha1&q-ak=AKIDnxL6LVTJBnUlNXnCUagKGUg8CdKFktVxR35hWaFDtUEt8RxhrdruOn-7m7iddOSy&q-sign-time=1699590851;1699594451&q-key-time=1699590851;1699594451&q-header-list=host&q-url-param-list=ci-process&q-signature=698f53879d3b14a969782b0cc639f582cd920d40&x-cos-security-token=B80XrI59VOTlXumQ1kq5eftQo3A9xvua85050068758525aa5f6998e190c85e16BF6FVkEVKiNVBubGA207yJv8eLMeq4HOEKclOENV3aQ0bnNUVb6cuROJ_O4Nqn7UcjXpdQ_HtruiLZmtX585N7NZFvv5vuPVjQqE7o2q6d7w8Hzul0aqOJVGNEYbVYqTdUpLWo3p0Ls5YJLE1VAP8B7QadC_4l5XiHn-Ei8WZMOF77Msa9V5x668v2-puTgC&ci-process=originImage" style="zoom:50%;" />

<p>这样我们就得到了Xt和X0的关系了</p>
<p>为了简化 方便描述 我们设$$\bar \alpha &#x3D; \alpha_t\alpha_{t-1}….\alpha_1$$</p>
<p>很好 我们现在得出:</p>
<p>$$X_t &#x3D; \sqrt{1-\bar\alpha}\epsilon+ \sqrt {\bar\alpha}X_0,\epsilon \backsim N(0,1) $$</p>
<p>$$ q(x_{t}|x_{0}) &#x3D; \frac{1}{\sqrt{2\pi } \sqrt{1-\bar{a}<em>{t}}} e^{\left ( -\frac{1}{2}\frac{(x</em>{t}-\sqrt{\bar{a}<em>{t}}x_0)^2}{1-\bar{a}</em>{t}} \right ) } $$</p>
<h3 id="2-2-反向推理"><a href="#2-2-反向推理" class="headerlink" title="2.2 反向推理"></a>2.2 反向推理</h3><p>通过刚刚的推导 我们理解了 在前向加噪的过程中发生的变化  </p>
<p><img src="C:\Users\86198\AppData\Roaming\Typora\typora-user-images\image-20231109153836778.png" alt="image-20231109153836778"></p>
<p>那么我们的目的是反向去噪生成模型  这个怎么实现呢？</p>
<p>我们可以用此关系 反向推理求出和X0的关系</p>
<p>知识点 ：贝叶斯定理</p>
<p><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/e08d4ab0386c0ebb7d87f398cd38f911440fe3da" alt="{\displaystyle P(A\mid B)={\frac {P(A)P(B\mid A)}{P(B)}}}"></p>
<p>我们的目标是$$X_t &#x3D; \sqrt{1-\bar\alpha}\epsilon_t+ \sqrt {\bar\alpha}X_{t-1}  $$</p>
<p>那么对于后验概率$$p(X_{t-1}|X_t)&#x3D;\cfrac{p(X_t|X_{t-1})p(X_{t-1})}{p(X_t)}$$</p>
<p>分别为$$X_t,X_{t-1}$$时刻的概率  也就是从X0推断出的概率</p>
<p>所以 我们 可以用另外一个形式来表示<br>$$<br>p(X_{t-1}|X_t,X_0)&#x3D;\cfrac{p(X_t|X_{t-1},X_0)p(X_{t-1}|X_0)}{p(X_t|X_0)}<br>$$<br> 至此 只要求解右边的式子 我们就可以知道给定Xt时刻,前一时刻$$X_{t-1}$$的概率</p>
<p> $$x_{t} &#x3D; \sqrt{a_t}x_{t-1}+\sqrt{1-a_t}\times ϵ$$ ~ $N(\sqrt{a_t}x_{t-1}, 1-a_{t})$</p>
<p>$$x_{t-1} &#x3D; \sqrt{\bar{a}<em>{t-1}}x_0+ \sqrt{1-\bar{a}</em>{t-1}}\times ϵ$$ ~  $N( \sqrt{\bar{a}<em>{t-1}}x_0, 1-\bar{a}</em>{t-1})$</p>
<p>  $$x_{t} &#x3D; \sqrt{\bar{a}<em>{t}}x_0+ \sqrt{1-\bar{a}</em>{t}}\times ϵ$$ ~   $N( \sqrt{\bar{a}<em>{t}}x_0, 1-\bar{a}</em>{t})$</p>
<p><strong>既然我们已知了不同阶段的正态分布函数，通过概率密度函数 我们可以求出该时刻的概率  将三者概率带入到我们的朴素贝叶斯公式中可以得出</strong></p>
<p>$$ q(x_{t}|x_{t-1},x_{0}) &#x3D; \frac{1}{\sqrt{2\pi } \sqrt{1-a_{t}}} e^{\left (  -\frac{1}{2}\frac{(x_{t}-\sqrt{a_t}x_{t-1})^2}{1-a_{t}}   \right ) } $$</p>
<p>推导过程如下：</p>
<p>$$ \frac{ q(x_{t}|x_{t-1},x_{0})\times q(x_{t-1}|x_0)}{q(x_{t}|x_0)} &#x3D; \left [<br>  \frac{1}{\sqrt{2\pi} \sqrt{1-a_{t}}} e^{\left (  -\frac{1}{2}\frac{(x_{t}-\sqrt{a_t}x_{t-1})^2}{1-a_{t}}   \right ) }<br>\right ] *<br>\left [<br>\frac{1}{\sqrt{2\pi} \sqrt{1-\bar{a}<em>{t-1}}} e^{\left (  -\frac{1}{2}\frac{(x</em>{t-1}-\sqrt{\bar{a}<em>{t-1}}x_0)^2}{1-\bar{a}</em>{t-1}}   \right ) }<br>\right ] \div<br>\left [<br>  \frac{1}{\sqrt{2\pi} \sqrt{1-\bar{a}<em>{t}}} e^{\left (  -\frac{1}{2}\frac{(x</em>{t}-\sqrt{\bar{a}<em>{t}}x_0)^2}{1-\bar{a}</em>{t}}   \right ) }<br>\right ]  $$</p>
<p>$$ \Downarrow  $$</p>
<p>$$ \frac{\sqrt{2\pi} \sqrt{1-\bar{a}<em>{t}}}{\sqrt{2\pi} \sqrt{1-a</em>{t}} \sqrt{2\pi} \sqrt{1-\bar{a}<em>{t-1}} }<br>e^{\left [  -\frac{1}{2}<br>\left (<br> \frac{(x</em>{t}-\sqrt{a_t}x_{t-1})^2}{1-a_{t}} +<br> \frac{(x_{t-1}-\sqrt{\bar{a}<em>{t-1}}x_0)^2}{1-\bar{a}</em>{t-1}} -<br> \frac{(x_{t}-\sqrt{\bar{a}<em>{t}}x_0)^2}{1-\bar{a}</em>{t}}<br> \right )<br>    \right ] } $$</p>
<p>$$ \Downarrow  $$</p>
<p>$$ \frac{1}{\sqrt{2\pi} \left ( \frac{ \sqrt{1-a_t} \sqrt{1-\bar{a}<em>{t-1}} } {\sqrt{1-\bar{a}</em>{t}}} \right ) }<br>exp{\left [  -\frac{1}{2}<br>\left (<br> \frac{(x_{t}-\sqrt{a_t}x_{t-1})^2}{1-a_t} +<br> \frac{(x_{t-1}-\sqrt{\bar{a}<em>{t-1}}x_0)^2}{1-\bar{a}</em>{t-1}} -<br> \frac{(x_{t}-\sqrt{\bar{a}<em>{t}}x_0)^2}{1-\bar{a}</em>{t}}<br> \right )<br>    \right ] } $$</p>
<p>$$ \Downarrow  $$</p>
<p>$$ \frac{1}{\sqrt{2\pi} \left ( \frac{ \sqrt{1-a_t} \sqrt{1-\bar{a}<em>{t-1}} } {\sqrt{1-\bar{a}</em>{t}}} \right ) }<br>exp \left[  -\frac{1}{2}<br>\left (<br> \frac{<br>   x_{t}^2-2\sqrt{a_t}x_{t}x_{t-1}+{a_t}x_{t-1}^2<br> }{1-a_t} +<br> \frac{<br>   x_{t-1}^2-2\sqrt{\bar{a}<em>{t-1}}x_0x</em>{t-1}+\bar{a}<em>{t-1}x_0^2<br>  }{1-\bar{a}</em>{t-1}} -<br> \frac{(x_{t}-\sqrt{\bar{a}<em>{t}}x_0)^2}{1-\bar{a}</em>{t}}<br>\right)<br>\right] $$</p>
<p>$$ \Downarrow  $$</p>
<p>$$ \frac{1}{\sqrt{2\pi} \left ( {\color{Red} \frac{ \sqrt{1-a_t} \sqrt{1-\bar{a}<em>{t-1}} } {\sqrt{1-\bar{a}</em>{t}}}}  \right ) }<br>exp \left[<br>-\frac{1}{2}<br>\frac{<br>  \left(<br>    x_{t-1} - \left(<br>      {\color{Purple} \frac{\sqrt{a_t}(1-\bar{a}<em>{t-1})}{1-\bar{a}<em>t}x_t<br>      +<br>      \frac{\sqrt{\bar{a}</em>{t-1}}(1-a_t)}{1-\bar{a}<em>t}x_0}<br>      \right)<br>  \right) ^2<br>} {   \left( {\color{Red} \frac{ \sqrt{1-a_t} \sqrt{1-\bar{a}</em>{t-1}} } {\sqrt{1-\bar{a}</em>{t}}}}  \right)^2 }<br>\right] $$</p>
<p>$$ \Downarrow  $$</p>
<p>$$ p(x_{t-1}|x_{t}) \sim N\left(<br>      {\color{Purple} \frac{\sqrt{a_t}(1-\bar{a}<em>{t-1})}{1-\bar{a}<em>t}x_t<br>      +<br>      \frac{\sqrt{\bar{a}</em>{t-1}}(1-a_t)}{1-\bar{a}<em>t}x_0}  ,<br>      \left( {\color{Red} \frac{ \sqrt{1-a_t} \sqrt{1-\bar{a}</em>{t-1}} } {\sqrt{1-\bar{a}</em>{t}}}}  \right)^2<br> \right) $$</p>
<p>求得反向推导的函数公式为</p>
<p>又因为 $x_{t} &#x3D; \sqrt{\bar{a}_t}\times x_0+ \sqrt{1-\bar{a}_t}\times ϵ$, $x_0 &#x3D; \frac{x_t - \sqrt{1-\bar{a}_t}\times ϵ}{\sqrt{\bar{a}_t}}$. 代换如上述函数可得</p>
<p>$$ p(x_{t-1}|x_{t}) \sim N\left(<br>      {\color{Purple} \frac{\sqrt{a_t}(1-\bar{a}_{t-1})}{1-\bar{a}<em>t}x_t<br>      +<br>      \frac{\sqrt{\bar{a}</em>{t-1}}(1-a_t)}{1-\bar{a}<em>t}\times \frac{x_t - \sqrt{1-\bar{a}<em>t}\times ϵ}{\sqrt{\bar{a}<em>t}} } ,<br>       {\color{Red} \frac{ \beta</em>{t} (1-\bar{a}</em>{t-1}) } { 1-\bar{a}</em>{t}}}<br> \right) $$</p>
<p>由此 我们知道  怎么通过概率反向推出原图片的过程</p>
<h3 id="3-3-代码实现"><a href="#3-3-代码实现" class="headerlink" title="3.3 代码实现"></a>3.3 代码实现</h3><p>通过上述的问题 我们可以了解到 DDPM模型 在神经网络中的结构  </p>
<p>详细见<a target="_blank" rel="noopener" href="https://colab.research.google.com/drive/1WQ0fZL199I4LjnfNL_Kgma5rznR7rJW0#scrollTo=4PFEXUY8J2Fe">colab DF</a></p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="https://kidoom.github.io">kidoom</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="https://kidoom.github.io/2023/11/09/DDPM%20%E4%BE%8B%E4%BC%9A%E7%89%88/">https://kidoom.github.io/2023/11/09/DDPM%20%E4%BE%8B%E4%BC%9A%E7%89%88/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"><div class="social-share" data-image="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="next-post pull-full"><a href="/2023/11/08/Probabilistic%20Diffusion%20Model%E6%A6%82%E7%8E%87%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%8C%E6%95%B4PyTorch%E4%BB%A3%E7%A0%81%E8%AF%A6%E7%BB%86%E8%A7%A3%E8%AF%BB/"><img class="next-cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">Next Post</div><div class="next_info"></div></div></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://s1.328888.xyz/2022/10/08/fWUT0.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">kidoom</div><div class="author-info__description"></div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">8</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">0</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">0</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/kidoom"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>Announcement</span></div><div class="announcement_content">记录学习历程</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Catalog</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#DDPM-%E6%A6%82%E7%8E%87%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B"><span class="toc-number">1.</span> <span class="toc-text">DDPM  概率扩散模型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%E5%89%8D%E6%8F%90%E5%BC%95%E5%85%A5%EF%BC%9A"><span class="toc-number">2.</span> <span class="toc-text">1. 前提引入：</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-1%E6%AD%A3%E6%80%81%E5%88%86%E5%B8%83"><span class="toc-number">2.1.</span> <span class="toc-text">1.1正态分布</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-2-%E6%89%A9%E6%95%A3"><span class="toc-number">2.2.</span> <span class="toc-text">1.2 扩散</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-DDPM"><span class="toc-number">3.</span> <span class="toc-text">2. DDPM:</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-%E5%89%8D%E5%90%91%E8%BF%87%E7%A8%8B%EF%BC%9A"><span class="toc-number">3.1.</span> <span class="toc-text">2.1 前向过程：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-%E5%8F%8D%E5%90%91%E6%8E%A8%E7%90%86"><span class="toc-number">3.2.</span> <span class="toc-text">2.2 反向推理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-3-%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0"><span class="toc-number">3.3.</span> <span class="toc-text">3.3 代码实现</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2023/11/09/DDPM%20%E4%BE%8B%E4%BC%9A%E7%89%88/" title="No title"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="No title"/></a><div class="content"><a class="title" href="/2023/11/09/DDPM%20%E4%BE%8B%E4%BC%9A%E7%89%88/" title="No title">No title</a><time datetime="2023-11-09T05:03:19.156Z" title="Created 2023-11-09 13:03:19">2023-11-09</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/11/08/Probabilistic%20Diffusion%20Model%E6%A6%82%E7%8E%87%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%8C%E6%95%B4PyTorch%E4%BB%A3%E7%A0%81%E8%AF%A6%E7%BB%86%E8%A7%A3%E8%AF%BB/" title="No title"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="No title"/></a><div class="content"><a class="title" href="/2023/11/08/Probabilistic%20Diffusion%20Model%E6%A6%82%E7%8E%87%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%8C%E6%95%B4PyTorch%E4%BB%A3%E7%A0%81%E8%AF%A6%E7%BB%86%E8%A7%A3%E8%AF%BB/" title="No title">No title</a><time datetime="2023-11-08T11:23:02.987Z" title="Created 2023-11-08 19:23:02">2023-11-08</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/11/08/%E4%BF%A1%E6%81%AF%E7%86%B5%20%20%E7%9B%B8%E5%AF%B9%E7%86%B5%20%20%E4%BA%A4%E5%8F%89%E7%86%B5%20%20KL%E6%95%A3%E5%BA%A6%20%20KL%20Divergence/" title="No title"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="No title"/></a><div class="content"><a class="title" href="/2023/11/08/%E4%BF%A1%E6%81%AF%E7%86%B5%20%20%E7%9B%B8%E5%AF%B9%E7%86%B5%20%20%E4%BA%A4%E5%8F%89%E7%86%B5%20%20KL%E6%95%A3%E5%BA%A6%20%20KL%20Divergence/" title="No title">No title</a><time datetime="2023-11-08T10:49:25.946Z" title="Created 2023-11-08 18:49:25">2023-11-08</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/11/07/diffusion_model/" title="No title"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="No title"/></a><div class="content"><a class="title" href="/2023/11/07/diffusion_model/" title="No title">No title</a><time datetime="2023-11-07T12:34:47.869Z" title="Created 2023-11-07 20:34:47">2023-11-07</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/10/14/ORM%E6%80%9D%E6%83%B3%E5%92%8C%E6%A1%86%E6%9E%B6%E5%AE%9E%E7%8E%B0/" title="ORM思想和框架实现（基于python）"><img src="https://blog-1314366587.cos.ap-nanjing.myqcloud.com/blog/images.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="ORM思想和框架实现（基于python）"/></a><div class="content"><a class="title" href="/2022/10/14/ORM%E6%80%9D%E6%83%B3%E5%92%8C%E6%A1%86%E6%9E%B6%E5%AE%9E%E7%8E%B0/" title="ORM思想和框架实现（基于python）">ORM思想和框架实现（基于python）</a><time datetime="2022-10-13T16:00:00.000Z" title="Created 2022-10-14 00:00:00">2022-10-14</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2023 By kidoom</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Switch Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle between single-column and double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="Back To Top"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><script>var preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',preloader.endLoading())</script><div class="js-pjax"></div><script id="canvas_nest" defer="defer" color="0,0,0" opacity="0.7" zIndex="-1" count="99" mobile="true" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-nest.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>